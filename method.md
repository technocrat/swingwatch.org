+++
title = "Methodology"
+++

## How the likelihood model is made

Among many other facts, one thing is known about the 2020 election in the seven swing states to a high degree of certainty—the [definitive outcomes](https://www.archives.gov/electoral-college/2020) in terms of the votes for the two top candidates and the number of electoral votes awarded. Under the rule of thumb that the future will look similar to the immediate past plus or minus a little, those outcomes provide a *starting* point for further analysis.

Subject to all the infirmities inherent in political preference, the results of swing state specific polling provides additional, provisional information about the 2024 election. The responses of polled votes to questions concrerning the relative level of support enjoyed by the two candidates for any recent period is, at least, some indictor of how the actual outcome should be expected. For this situation we can adjust the results of the 2020 election based on currrent presidential preference primary polling through a process known as Bayesian modeling. 

Here is a short [chatGPT](https://open.ai) summary:

Bayesian modeling is a statistical approach that provides a flexible way of learning from data. Unlike traditional statistics, which often starts from the assumption that nothing is known until data is observed, Bayesian modeling begins with prior beliefs or existing knowledge about what the results *might* be. These beliefs are then updated with new data to form more refined conclusions.

Here’s how it works: Imagine you're trying to guess the number of candies in a jar. Before counting or seeing inside the jar, you might already have a rough idea based on your past experiences with similar jars—this is your "prior" belief. As you observe or gather more information (perhaps by looking at how many layers of candies there seem to be), you update your original guess. This process of updating is based on Bayes' theorem, which mathematically combines your prior beliefs with the new evidence.

The result is a "posterior" probability, which tells you how likely different candy counts are, *given* both your initial guess and whatever new information you've gathered. Over time, as more data is collected, your posterior probabilities get sharper and more focused, leading you to a more precise estimation. 

Bayesian modeling is particularly powerful because it can adapt to complex real-world problems, incorporate uncertainty explicitly, and handle various types of data. It's widely used in fields ranging from genetics to economics, helping experts make better decisions under uncertainty.



